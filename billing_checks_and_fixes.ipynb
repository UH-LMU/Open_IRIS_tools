{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kBqCVIAyjZTI"
   },
   "source": [
    "# Usage on Windows\n",
    "## Prerequisites\n",
    "- Install Anaconda (in Software Center on UH computers).\n",
    "- Download this notebook and the invoice from Open IRIS in a folder.\n",
    "- Start Menu -> Anaconda -> Anaconda shell.\n",
    "- In the shell: \"cd\" to the folder with the notebook, e.g. \"cd Documents\\billing_check\".\n",
    "- In the shell: \"jupyter notebook\". This chould open the notebook in a browser.\n",
    "\n",
    "## Run the notebook\n",
    "- Change the invoice file name in the first notebook cell.\n",
    "- Cell -> Run All.\n",
    "- Wait for .xslx files to appear in the folder.\n",
    "- 1st run creates InvoiceNN__with_owners.xlsx file.\n",
    "\n",
    "## Check cell output\n",
    "The following cells run test that produce results in .xlsx files:\n",
    "- Manual interventions\n",
    "- Check totals before any fixes\n",
    "- Save test files after fixes\n",
    "\n",
    "The cell output shows the (rows,cols) count of the test result. If there are more than 0 rows, you can check the .xlsx.\n",
    "\n",
    "## Manual corrections\n",
    "You can use the test .xlsx files as starting point for corrections. This is more convenient than editing the complete invoice from IRIS. The changes can be merged to the complete invoice with the notebook merge_xlsx.ipynb.\n",
    "\n",
    "As an example, let's say you want to add missing price types:\n",
    "- Open test_InvoiceNN__price_type_missing.xlsx.\n",
    "- Make corrections.\n",
    "- Save as fixed_InvoiceNN__price_type_missing.xlsx (to prevent corrections being over-written).\n",
    "- Run merge_xlsx.ipynb with FIXES_FILE = 'fixed_InvoiceNN__price_type_missing.xlsx' and INVOICE_FILE = 'InvoiceNN__with_owners.xlsx'.\n",
    "- Run this notebook from the beginning. Do not change invoice from the first run.\n",
    "\n",
    "merge_xlsx.ipynb creates timestamped versions of the invoice. To undo manual corrections, delete the corresponding versions from the invoice folder.\n",
    "\n",
    "## Add product purchases\n",
    "As the final step, you can append product purchases to the invoice. This can be done with merge_xlsx notebook. Please note that as the product rows do not contain most columns in the invoice, the resulting .xlsx will not work in this notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "raweyeFKlGb7"
   },
   "source": [
    "# Connect to Google Drive from Colaboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3hh-7v7Dk_0f"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3pJmyFKwk777"
   },
   "source": [
    "# Price list and invoice\n",
    "- set invoice file\n",
    "- set holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "5xTevWuXmTRs"
   },
   "outputs": [],
   "source": [
    "# '.' works on local computer when the price list is in the notebook folder\n",
    "PRICE_LIST_DIR = '.' \n",
    "\n",
    "# comment out price list you don't want to use\n",
    "#PRICE_LIST_FILE = 'price_list_biu.csv' \n",
    "PRICE_LIST_FILE = 'price_list_lmu.csv' \n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "INVOICE_DIR = './data/LMU/39' \n",
    "#INVOICE_DIR = 'C:\\\\Users\\\\hajaalin\\\\Downloads\\\\LMU39'\n",
    "INVOICE_NAME = 'Invoice39.xlsx'\n",
    "REQUESTS_NAME = 'Light Microscopy Unit-provider-requests.xlsx'\n",
    "\n",
    "# If you want bookings by BIU and/or LMU to appear in the fixed invoice, \n",
    "# set the flags below to True. Otherwise they will be filtered out and will\n",
    "# appear only in 'test_InvoiceNN__[BIU,LMU]_bookings.xlsx'\n",
    "INVOICE_BIU_GROUPS = True\n",
    "INVOICE_LMU_GROUPS = False\n",
    "\n",
    "\n",
    "from utils import find_latest_invoice_version\n",
    "\n",
    "PRICE_LIST_DIR = Path(PRICE_LIST_DIR)\n",
    "if not PRICE_LIST_DIR.is_dir():\n",
    "    raise ValueError('Please check PRICE_LIST_DIR.')\n",
    "PRICE_LIST_FILE = PRICE_LIST_DIR / PRICE_LIST_FILE\n",
    "if not PRICE_LIST_FILE.exists():\n",
    "    raise ValueError('Please check PRICE_LIST_FILE.')\n",
    "\n",
    "INVOICE_DIR = Path(INVOICE_DIR)\n",
    "if not INVOICE_DIR.is_dir():\n",
    "    raise ValueError('Please check INVOICE_DIR.')\n",
    "INVOICE_FILE = INVOICE_DIR / INVOICE_NAME\n",
    "if not INVOICE_FILE.exists():\n",
    "    raise ValueError('Please check INVOICE_NAME.')\n",
    "REQUESTS_FILE = INVOICE_DIR / REQUESTS_NAME\n",
    "if not REQUESTS_FILE.exists():\n",
    "    raise ValueError('Please check REQUESTS_NAME.')\n",
    "\n",
    "DEBUG_DIR = INVOICE_DIR / 'debug'\n",
    "DEBUG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "basename = Path(INVOICE_NAME).stem\n",
    "ext = Path(INVOICE_NAME).suffix\n",
    "\n",
    "# read first two rows of input\n",
    "header = pd.read_excel(INVOICE_FILE, nrows=1)\n",
    "\n",
    "# check if the first two rows are the invoice summary from IRIS\n",
    "if 'Created by' in header.columns:\n",
    "    header = header[header.columns.drop(list(header.filter(regex='Unnamed')))]\n",
    "    header.to_excel(INVOICE_DIR / (basename + \"__header.xlsx\"), index=False)\n",
    "    df = pd.read_excel(INVOICE_FILE, skiprows=[0,1])\n",
    "else:\n",
    "    header = pd.DataFrame() # use empty dataframe as marker\n",
    "    df = pd.read_excel(INVOICE_FILE)\n",
    "    \n",
    "# add project owner columns from project list\n",
    "# this should be done only once, so if the file exists, don't redo\n",
    "INVOICE_WITH_OWNERS = INVOICE_DIR / (basename + \"__with_owners.xlsx\")\n",
    "COL_REQUEST_ID = 'Request ID'\n",
    "COL_REQUESTER_EMAIL = 'Requester email'\n",
    "COL_REQUESTER_NAME = 'Requester name'\n",
    "if INVOICE_WITH_OWNERS.exists():\n",
    "    INVOICE_WITH_OWNERS = find_latest_invoice_version(INVOICE_WITH_OWNERS)\n",
    "    df = pd.read_excel(INVOICE_WITH_OWNERS)\n",
    "else:\n",
    "    req = pd.read_excel(REQUESTS_FILE)\n",
    "    req = req[[COL_REQUEST_ID, COL_REQUESTER_EMAIL, COL_REQUESTER_NAME]]\n",
    "    df = pd.merge(df, req, on=COL_REQUEST_ID)\n",
    "    df.to_excel(INVOICE_WITH_OWNERS, index=False)\n",
    "\n",
    "print(INVOICE_WITH_OWNERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oKjxBKUkjZTN"
   },
   "outputs": [],
   "source": [
    "from datetime import date,datetime,timedelta\n",
    "import numpy as np\n",
    "\n",
    "# holidays during billing period (have to list manually)\n",
    "holidays = [\\\n",
    "    date(2019,12,6), \\\n",
    "    date(2019,12,24), \\\n",
    "    date(2019,12,25), \\\n",
    "    date(2019,12,26), \\\n",
    "    date(2020,1,1), \\\n",
    "    date(2020,1,6), \\\n",
    "    date(2020,4,10), \\\n",
    "    date(2020,4,13), \\\n",
    "    date(2020,5,1), \\\n",
    "    date(2020,5,21), \\\n",
    "    date(2020,6,19), \\\n",
    "    date(2020,12,6), \\\n",
    "    date(2020,12,24), \\\n",
    "    date(2020,12,25), \\\n",
    "    date(2020,12,26), \\\n",
    "    date(2021,1,1), \\\n",
    "    date(2021,1,6), \\\n",
    "    date(2021,4,2), \\\n",
    "    date(2021,4,5), \\\n",
    "    date(2021,5,1), \\\n",
    "    date(2021,5,13), \\\n",
    "    date(2021,6,25), \\\n",
    "    date(2021,12,6), \\\n",
    "    date(2021,12,24), \\\n",
    "    date(2021,12,25), \\\n",
    "    date(2021,12,26), \\\n",
    "    date(2022,1,1), \\\n",
    "    date(2022,1,6), \\\n",
    "    date(2022,4,15), \\\n",
    "    date(2022,4,18), \\\n",
    "    date(2022,5,1), \\\n",
    "    date(2022,5,26), \\\n",
    "    date(2022,6,24), \\\n",
    "    date(2022,12,6), \\\n",
    "    date(2022,12,24), \\\n",
    "    date(2022,12,25), \\\n",
    "    date(2022,12,26), \\\n",
    "    date(2023,1,1), \\\n",
    "    date(2023,1,6), \\\n",
    "    date(2023,4,6), \\\n",
    "    date(2023,4,10), \\\n",
    "    date(2023,5,1), \\\n",
    "    date(2023,5,18), \\\n",
    "    date(2023,6,23), \\\n",
    "           ]\n",
    "\n",
    "\n",
    "RESOURCE = 'Resource/Product'\n",
    "# essential columns shown in testing\n",
    "summary = ['ID','User name',RESOURCE,'Booking start','Booking end', 'Quantity','Price type','Charge','Group','Cost center name','Cost center code','Discount', 'Comments (charge)','Price (detailed)']\n",
    "summary_long = ['ID','User name',RESOURCE,'Booking start','Booking end','Price','Discount', 'Quantity','Price item','Price type','Charge','Group','Cost center name','Cost center code', 'Comments (charge)','Price (detailed)']\n",
    "summary_short = ['ID','User name',RESOURCE,'Booking start','Booking end','Quantity','Charge','Discount', 'Comments (charge)','Group','Cost center name','Cost center code']\n",
    "\n",
    "\n",
    "# exclude IRIS test instruments\n",
    "test_instruments = ['Sheep (TESTING AND DEVELOPMENT PURPOSE', 'Super testers practice instrument']\n",
    "df = df[~df[RESOURCE].isin(test_instruments)]\n",
    "\n",
    "# exclude (first save) staff groups\n",
    "biu_groups = ['BIU staff', 'BIU Task test']\n",
    "lmu_groups = ['Tanhuanpää Kimmo', 'LMU-staff']\n",
    "test_groups = ['Group Raimi research inc']\n",
    "\n",
    "cols = summary.copy()\n",
    "cols.append('Booking title')\n",
    "cols.append('Booking comments')\n",
    "df[df['Group'].isin(biu_groups)][cols].to_excel(INVOICE_DIR / (\"tmp_\" + basename + \"__BIU_bookings.xlsx\"), index=True)\n",
    "df[df['Group'].isin(lmu_groups)][cols].to_excel(INVOICE_DIR / (\"tmp_\" + basename + \"__LMU_bookings.xlsx\"), index=True)\n",
    "\n",
    "exclude_groups = []\n",
    "if not INVOICE_BIU_GROUPS:\n",
    "    exclude_groups.extend(biu_groups)\n",
    "if not INVOICE_LMU_GROUPS:\n",
    "    exclude_groups.extend(lmu_groups)\n",
    "exclude_groups.extend(test_groups)\n",
    "df = df[~df['Group'].isin(exclude_groups)]\n",
    "\n",
    "# store original report with essential columns\n",
    "df[summary].to_excel(DEBUG_DIR / (\"tmp_\" + basename + \"__summary\" + ext), index=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2769,
     "status": "ok",
     "timestamp": 1586432191662,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "",
      "userId": "10358975484852623681"
     },
     "user_tz": -180
    },
    "id": "XWceBWzcsmiG",
    "outputId": "837e23e5-4947-4dd2-9535-30938393717f"
   },
   "outputs": [],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Waived']==True][summary]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual interventions\n",
    "This cell saves rows that might need manual editing and test cases that are not expected\n",
    "to be changed by the automated fixes below.\n",
    "\n",
    "You can make the manual edits in the shorter .xlsx files produced here, and then merge the changes to the original IRIS report using the notebook \"merge_reports.ipynb\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRICE_TYPE = 'Price type'\n",
    "PRIME_TIME = 'Prime-time'\n",
    "OFF_HOURS = 'Off-hours'\n",
    "NIGHT_TIME = 'Night time'\n",
    "CANCELLATION_FEE = 'Cancellation fee'\n",
    "TRAINING_FEE = \"Training fee\"\n",
    "REBOOKED = 'Rebooked'\n",
    "\n",
    "def save_test_result(filename,dataframe,where=INVOICE_DIR):\n",
    "    print(filename + \" (rows, cols) \" + str(dataframe.shape))\n",
    "    dataframe.to_excel(where / filename, index=True)\n",
    "\n",
    "# save rows with price type missing\n",
    "test = df[df[PRICE_TYPE].isnull()]\n",
    "save_test_result(\"test_\" + basename + \"__price_type_missing.xlsx\", test[summary])\n",
    "\n",
    "# save rows with request ID missing\n",
    "test = df[df['Request ID'].isnull()]\n",
    "save_test_result(\"test_\" + basename + \"__request_id_missing.xlsx\", test[summary])\n",
    "\n",
    "# save rows with request ID missing\n",
    "test = df[df[COL_REQUESTER_NAME].isnull()]\n",
    "save_test_result(\"test_\" + basename + \"__requester_name_missing.xlsx\", test[summary], where=DEBUG_DIR)\n",
    "\n",
    "# group or WBS missing\n",
    "test = df[(df['Group'].isnull()) | (df['Cost center code'].isnull())][summary_short]\n",
    "save_test_result(\"test_\" + basename + '__group_or_wbs_missing.xlsx', test)\n",
    "\n",
    "# remit code missing\n",
    "test = df[df['Remit code'].isnull()][summary_short]\n",
    "save_test_result(\"test_\" + basename + '__remit_code_missing.xlsx', test)\n",
    "\n",
    "# save rows with cancellations\n",
    "test = df[df['Price item'].str.contains(\"Cancellation\")]\n",
    "save_test_result(\"test_\" + basename + \"__cancellations.xlsx\", test[summary_short], where=DEBUG_DIR)\n",
    "\n",
    "# save rows with commented cancellations\n",
    "test = df[(df['Price item'].str.contains(\"Cancellation\")) & (~df['Booking comments'].isnull())]\n",
    "cols = summary_short.copy()\n",
    "cols.append('Booking comments')\n",
    "save_test_result(\"test_\" + basename + \"__cancellation_reasons.xlsx\", test[cols])\n",
    "\n",
    "# save rows with discounts\n",
    "test = df[~df['Discount'].isnull()]\n",
    "save_test_result(\"test_\" + basename + \"__discount.xlsx\", test[summary_short], where=DEBUG_DIR)\n",
    "\n",
    "# save rows with waived charges\n",
    "test = df[df['Waived']==True]\n",
    "save_test_result(\"test_\" + basename + \"__waived.xlsx\", test[summary], where=DEBUG_DIR)\n",
    "\n",
    "# save rows with no PI email\n",
    "test = df[df['Group head(s) text'].isnull()]\n",
    "cols = summary_short.copy()\n",
    "cols.append('Group head(s) text')\n",
    "save_test_result(\"test_\" + basename + \"__pi_email_missing.xlsx\", test[cols])\n",
    "\n",
    "\n",
    "# find product rows\n",
    "if not 'tmp_is_product' in df.columns:\n",
    "    df['tmp_is_product'] = df['Charge type']=='Product (request)'\n",
    "products = df[df['tmp_is_product']].copy()\n",
    "\n",
    "# fix product rows in main invoice (to avoid missing price)\n",
    "for i in products.index:\n",
    "    df.at[i,RESOURCE] = df.loc[i]['Price list/Product']\n",
    "\n",
    "# remove whitespace\n",
    "df[RESOURCE] = df[RESOURCE].astype(str)\n",
    "df[RESOURCE] = df[RESOURCE].str.strip()\n",
    "\n",
    "# find proper values for product name, user who bought the product, purchase date\n",
    "products[RESOURCE] = products['Price list/Product']\n",
    "products['User name'] = products['Product comments']\n",
    "products['Booking start'] = products['Product purchase date'] ## TODO: 'Charge date'?\n",
    "products['Booking end'] = products['Product purchase date']\n",
    "\n",
    "# save product rows\n",
    "cols = ['ID','Product comments',RESOURCE,'Booking start','Booking end','Quantity','Charge','Discount', 'Comments (charge)','Group','Cost center name','Cost center code']\n",
    "save_test_result(\"test_\" + basename + \"__products.xlsx\", products[cols], where=INVOICE_DIR)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read price list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[RESOURCE].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mg5AIZzGjZTt"
   },
   "outputs": [],
   "source": [
    "prices = pd.read_csv(PRICE_LIST_FILE, quotechar=\"'\",)\n",
    "\n",
    "print('Price types in use:')\n",
    "print(df[PRICE_TYPE].unique())\n",
    "\n",
    "# Add price item for training, with same price as PRIME_TIME\n",
    "prices[TRAINING_FEE] = prices[PRIME_TIME]\n",
    "\n",
    "# Check that prices exist for all instruments\n",
    "for r in df[RESOURCE].unique():\n",
    "    for pt in df[PRICE_TYPE].unique():\n",
    "        for p in [PRIME_TIME,OFF_HOURS,NIGHT_TIME]:\n",
    "            try:\n",
    "                mask = (prices.Instrument == r) & (prices[PRICE_TYPE] == pt)\n",
    "                #print(\"'%s'\" % r)\n",
    "                price = prices[mask].values[0]\n",
    "            except:\n",
    "                raise ValueError(\"Price missing: %s / %s / %s\" % (r,pt,p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQM9DfO1jZUV"
   },
   "source": [
    "# Functions and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1O9JAKyejZUX"
   },
   "outputs": [],
   "source": [
    "# read these columns as datetime\n",
    "df['Booking start'] =  pd.to_datetime(df['Booking start'], format='%Y-%m-%d %H:%M')\n",
    "df['Booking end'] =  pd.to_datetime(df['Booking end'], format='%Y-%m-%d %H:%M')\n",
    "\n",
    "# force wbs codes to be string\n",
    "df['Cost center code'] =  df['Cost center code'].astype(str)\n",
    "products['Cost center code'] =  products['Cost center code'].astype(str)\n",
    "\n",
    "# billing period\n",
    "period_start = df['Booking start'].min().date()\n",
    "period_end = df['Booking end'].max().date()\n",
    "\n",
    "# weekends during billing period\n",
    "weekends = []\n",
    "test = period_start\n",
    "while test < period_end:\n",
    "    if test.weekday() >= 5:\n",
    "        weekends.append(test)\n",
    "    test = test + timedelta(days=1)\n",
    "weekends\n",
    "\n",
    "weekends_and_holidays = sorted(weekends + holidays)\n",
    "\n",
    "instruments_with_night_discounts = prices[~prices[NIGHT_TIME].isnull()]['Instrument'].unique()\n",
    "instruments_with_no_discounts = prices[(prices[PRIME_TIME] == prices[OFF_HOURS]) & \\\n",
    "                                             (prices[NIGHT_TIME].isnull())]['Instrument'].unique()\n",
    "instruments_with_cancellation_fee = prices[~prices[CANCELLATION_FEE].isnull()]['Instrument'].unique()\n",
    "print('instruments_with_night_discounts')\n",
    "print(instruments_with_night_discounts)\n",
    "print('instruments_with_no_discounts')\n",
    "print(instruments_with_no_discounts)\n",
    "print('instruments_with_cancellation_fee')\n",
    "print(instruments_with_cancellation_fee)\n",
    "\n",
    "\n",
    "def next_workday(dt):\n",
    "    #print(weekends_and_holidays)\n",
    "    test = dt\n",
    "    while True:\n",
    "        test = test + timedelta(days=1)\n",
    "        #print(test.date())\n",
    "        if test.date() not in weekends_and_holidays:\n",
    "            return test\n",
    "\n",
    "# get price type for a booking that has already been split\n",
    "def get_price_item(row):\n",
    "    if (row['tmp_cancellation'] == True):\n",
    "        if (row['tmp_rebooked'] == True):\n",
    "            return REBOOKED\n",
    "        else:\n",
    "            return CANCELLATION_FEE\n",
    "        \n",
    "    if \"Training\" in row['tmp_price_item_iris']:\n",
    "        return TRAINING_FEE\n",
    "\n",
    "    if row[RESOURCE] in instruments_with_night_discounts:\n",
    "        if row['Booking start'].hour < 8 or row['Booking start'].hour >= 22:\n",
    "            return NIGHT_TIME\n",
    "        if includes_holiday_or_weekend(row) or row['Booking start'].hour == 8 or row['Booking start'].hour >= 17:\n",
    "            return OFF_HOURS\n",
    "        else:\n",
    "            return PRIME_TIME\n",
    "    else:\n",
    "        if includes_holiday_or_weekend(row) or row['Booking start'].hour < 9 or row['Booking start'].hour >= 17:\n",
    "            return OFF_HOURS\n",
    "        else:\n",
    "            return PRIME_TIME\n",
    "        \n",
    "def get_price(row):\n",
    "    #print(row[[RESOURCE,PRICE_TYPE]])\n",
    "    #print(get_price_item(row))\n",
    "    if get_price_item(row) == REBOOKED:\n",
    "        return 0\n",
    "\n",
    "    return prices[(prices['Instrument'] == row[RESOURCE]) & \\\n",
    "                  (prices[PRICE_TYPE] == row[PRICE_TYPE])][get_price_item(row)].values[0]\n",
    "\n",
    "def get_discount_factor(row):\n",
    "    discount = row['Discount']\n",
    "    discount = discount.replace('%','')\n",
    "    if(discount == 'nan'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 1 - float(discount)/100\n",
    "\n",
    "df['Discount'] = df['Discount'].astype(str)\n",
    "df['tmp_discount_factor'] = 1\n",
    "df['tmp_discount_factor'] = df.apply(get_discount_factor, axis=1)\n",
    "test = df[df['tmp_discount_factor'] != 1]\n",
    "cols = summary_short.copy()\n",
    "cols.append('tmp_discount_factor')\n",
    "save_test_result(\"test_\" + basename + \"__discount_factor.xlsx\", test[cols], where=DEBUG_DIR)\n",
    "\n",
    "# splits between prime and off hours (no night discount)\n",
    "def next_split_2(dt):\n",
    "    # other to prime time\n",
    "    if dt.hour >= 17:\n",
    "        nwd = next_workday(dt)\n",
    "        return datetime(nwd.year,nwd.month,nwd.day,9,0,0)\n",
    "    if dt.hour < 9:\n",
    "        if dt.date() not in weekends_and_holidays:\n",
    "            return datetime(dt.year,dt.month,dt.day,9,0,0)\n",
    "        else:\n",
    "            nwd = next_workday(dt)\n",
    "            return datetime(nwd.year,nwd.month,nwd.day,9,0,0) \n",
    "    # prime to other time\n",
    "    if dt.hour < 17:\n",
    "        if dt.date() not in weekends_and_holidays:\n",
    "            return datetime(dt.year,dt.month,dt.day,17,0,0)\n",
    "        else:\n",
    "            nwd = next_workday(dt)\n",
    "            return datetime(nwd.year,nwd.month,nwd.day,9,0,0) \n",
    "    \n",
    "# splits between prime, off and night hours \n",
    "def next_split_3(dt):\n",
    "    # night to other time\n",
    "    if dt.hour >= 22:\n",
    "        return datetime(dt.year,dt.month,dt.day,8,0,0) + timedelta(days=1)\n",
    "    if dt.hour < 8:\n",
    "        return datetime(dt.year,dt.month,dt.day,8,0,0)\n",
    "    # other to prime time (or night time during holidays)\n",
    "    if dt.hour < 9:\n",
    "        if (dt.date() in weekends_and_holidays):\n",
    "            return datetime(dt.year,dt.month,dt.day,22,0,0)\n",
    "        else:\n",
    "            return datetime(dt.year,dt.month,dt.day,9,0,0)\n",
    "    # prime to other time (or night time during holidays)\n",
    "    if dt.hour < 17:\n",
    "        if (dt.date() in weekends_and_holidays):\n",
    "            return datetime(dt.year,dt.month,dt.day,22,0,0)\n",
    "        else:\n",
    "            return datetime(dt.year,dt.month,dt.day,17,0,0)\n",
    "    # other to night time\n",
    "    if dt.hour < 22:\n",
    "        return datetime(dt.year,dt.month,dt.day,22,0,0)\n",
    "    \n",
    "# does a row need prime/off split\n",
    "def needs_split_2(row):\n",
    "    if row[RESOURCE] in np.append(instruments_with_night_discounts,instruments_with_no_discounts):\n",
    "        return False\n",
    "    if next_split_2(row['Booking start']) < row['Booking end']:\n",
    "        #print('start ' + str(row['Booking start']))\n",
    "        #print('next ' + str(next_split_2(row['Booking start'])))\n",
    "        #print('end ' + str(row['Booking end']))\n",
    "        #print(\"yes\")\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# does a row need prime/off/night split\n",
    "def needs_split_3(row):\n",
    "    if not row[RESOURCE] in instruments_with_night_discounts:\n",
    "        return False\n",
    "    if next_split_3(row['Booking start']) < row['Booking end']:\n",
    "        #print('start ' + str(row['Booking start']))\n",
    "        #print('next ' + str(next_split_3(row['Booking start'])))\n",
    "        #print('end ' + str(row['Booking end']))\n",
    "        #print(\"yes\")\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def night_discount_applies(row):\n",
    "    if row[RESOURCE] in instruments_with_night_discounts:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def off_hour_discount_applies(row):\n",
    "    if row[RESOURCE] in instruments_with_no_discounts:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def cancellation_fee_applies(row):\n",
    "    if row[RESOURCE] in instruments_with_cancellation_fee:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_night_1(row):\n",
    "    if not night_discount_applies(row):\n",
    "        return False\n",
    "    #print(row.head())\n",
    "    dt1 = row['Booking start']\n",
    "    dt2 = row['Booking end']\n",
    "    if dt2 > datetime(dt1.year, dt1.month, dt1.day, 22, 0, 0):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_night_2(row):\n",
    "    if not night_discount_applies(row):\n",
    "        return False\n",
    "    #print(row.head())\n",
    "    dt1 = row['Booking start']\n",
    "    dt2 = row['Booking end']\n",
    "    if (dt1.day < dt2.day) or (dt1.hour < 8):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_cancellation(row):\n",
    "    if \"Cancellation\" in row['Price item']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def includes_holiday_or_weekend(row):\n",
    "    d1 = row['Booking start'].date()\n",
    "    d2 = row['Booking end'].date()\n",
    "\n",
    "    for dt in weekends_and_holidays:\n",
    "        if (d1 <= dt) and (d2 >= dt):\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "def calculate_duration(row):\n",
    "    delta = row['Booking end'] - row['Booking start']\n",
    "    return round(delta.total_seconds() / 3600, 4)\n",
    "\n",
    "\n",
    "def calculate_charge(row):\n",
    "    # leave cancellations as they are\n",
    "    if row['tmp_cancellation_fee_applies'] and row['tmp_cancellation']:\n",
    "        return row['Charge']\n",
    "    \n",
    "    if row['Waived'] == True:\n",
    "        return 0\n",
    "    \n",
    "    return round(row['Quantity'] * row['Price'] * row['tmp_discount_factor'], 2)\n",
    "\n",
    "\n",
    "def split_3(rows):\n",
    "    _summary = ['ID','Booking start','Booking end','Price']\n",
    "\n",
    "    # make a copy, just to be sure\n",
    "    rows = rows.copy()\n",
    "    #print(\"rows:\")\n",
    "    #print(rows[_summary])\n",
    "    \n",
    "    rows['Booking start'] =  pd.to_datetime(rows['Booking start'], format='%Y-%m-%d %H:%M')\n",
    "    rows['Booking end'] =  pd.to_datetime(rows['Booking end'], format='%Y-%m-%d %H:%M')\n",
    "\n",
    "    tmp = rows.tail(1).copy()\n",
    "    #print(\"tmp:\")\n",
    "    #print(tmp[_summary])\n",
    "    tmp['Booking start'] =  pd.to_datetime(tmp['Booking start'], format='%Y-%m-%d %H:%M')\n",
    "    tmp['Booking end'] =  pd.to_datetime(tmp['Booking end'], format='%Y-%m-%d %H:%M')\n",
    "    i = tmp.index.values[0]\n",
    "    #print(i)\n",
    "    next_split = next_split_3(tmp.loc[i]['Booking start'])\n",
    "    \n",
    "    if tmp.loc[i]['Booking end'] <= next_split:\n",
    "        #print(\"return split\")\n",
    "        rows['Price item'] = rows.apply(get_price_item, axis=1)\n",
    "        rows['Price'] = rows.apply(get_price, axis=1)\n",
    "        rows['Quantity'] = rows.apply(calculate_duration, axis=1)\n",
    "        rows['Charge'] = rows.apply(calculate_charge, axis=1)\n",
    "\n",
    "        return rows\n",
    "    \n",
    "    else:\n",
    "        rows.at[i,'Booking end'] = next_split\n",
    "        \n",
    "        tmp.at[i,'Booking start'] = next_split\n",
    "        rows = rows.append(tmp)\n",
    "        rows.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        return split_3(rows)\n",
    "    \n",
    "from utils import check_totals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gTuAB4_qjZUo"
   },
   "source": [
    "# Check totals before any fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3428,
     "status": "ok",
     "timestamp": 1586432192351,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "",
      "userId": "10358975484852623681"
     },
     "user_tz": -180
    },
    "id": "FWTOGtzQjZUq",
    "outputId": "d16f6319-d69b-4a44-fe8f-812d6f72d830"
   },
   "outputs": [],
   "source": [
    "check_totals(df,'before_fixes',DEBUG_DIR,basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split invoice to bookings and products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove products from main invoice\n",
    "df = df[~df['tmp_is_product']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add missing discounts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = summary_short.copy()\n",
    "cols.append('Booking ID')\n",
    "cols.append('tmp_discount_factor')\n",
    "\n",
    "# find split lines with discounts\n",
    "test = df[(df.duplicated(subset=['Booking ID'], keep=False)) & (df['tmp_discount_factor'] != 1)]\n",
    "save_test_result(\"test_\" + basename + \"__discount_with_split.xlsx\", test[cols], where=DEBUG_DIR)\n",
    "\n",
    "for i in test.index:\n",
    "    bookingID = df.loc[i]['Booking ID']\n",
    "    discount = df.loc[i]['Discount']\n",
    "    discount_factor = df.loc[i]['tmp_discount_factor']\n",
    "    \n",
    "    # find all lines with this bookingID\n",
    "    for j in df[df['Booking ID'] == bookingID].index:\n",
    "        # apply the same discount\n",
    "        df.at[j,'Discount'] = discount\n",
    "        df.at[j,'tmp_discount_factor'] = discount_factor\n",
    "\n",
    "test = df[(df.duplicated(subset=['Booking ID'], keep=False)) & (df['tmp_discount_factor'] != 1)]\n",
    "save_test_result(\"test_\" + basename + \"__discount_with_split_fixed.xlsx\", test[cols], where=DEBUG_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply price list\n",
    "Overwrite IRIS prices with the .csv price list. Recalculate charges assuming that bookings are split (apply price item based on start time). \n",
    "\n",
    "Note: this will not be needed once IRIS has night prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store original price and charge in a new columns\n",
    "df['tmp_price_item_iris'] = df['Price item']\n",
    "df['tmp_price_iris'] = df['Price']\n",
    "df['tmp_quantity_iris'] = df['Quantity']\n",
    "df['tmp_charge_iris'] = df['Charge']\n",
    "\n",
    "# store info about cancellations. \n",
    "df['tmp_cancellation_fee_applies'] = df.apply(cancellation_fee_applies, axis=1)\n",
    "df['tmp_cancellation'] = df.apply(is_cancellation, axis=1)\n",
    "# this flag can be set manually to indicate (parts of) cancelled bookings that have been rebooked.\n",
    "if 'tmp_rebooked' not in df.columns:\n",
    "    print('column tmp_rebooked does not exist, creating...')\n",
    "    df['tmp_rebooked'] = False\n",
    "\n",
    "df['Price item'] = df.apply(get_price_item, axis=1)\n",
    "df['Price'] = df.apply(get_price, axis=1)\n",
    "\n",
    "## Recalculating durations and charges may be useful if merging data with manually added rows.\n",
    "df['Quantity'] = df.apply(calculate_duration, axis=1)\n",
    "df['Charge'] = df.apply(calculate_charge, axis=1)\n",
    "\n",
    "check_totals(df,'after_recalculate_charges',DEBUG_DIR,basename)\n",
    "\n",
    "# save training bookings\n",
    "cols = summary_short.copy()\n",
    "cols.append('tmp_price_item_iris')\n",
    "test = df[df['tmp_price_item_iris'].str.contains(\"Training\")]\n",
    "save_test_result(\"test_\" + basename + \"__trainings.xlsx\", test[cols], where=DEBUG_DIR)\n",
    "\n",
    "# save rows where duration changes\n",
    "cols = summary_short.copy()\n",
    "cols.append('tmp_quantity_iris')\n",
    "test = df[df['Quantity'] != df['tmp_quantity_iris']]\n",
    "save_test_result(\"test_\" + basename + \"__duration_changed.xlsx\", test[cols], where=DEBUG_DIR)\n",
    "\n",
    "# save rows where charge changes\n",
    "df['tmp_charge_diff'] = df['Charge'] - df['tmp_charge_iris']\n",
    "cols = summary_short.copy()\n",
    "cols.append('tmp_charge_iris')\n",
    "cols.append('tmp_charge_diff')\n",
    "# ignore differences under 1 EUR.\n",
    "test = df[df['tmp_charge_diff'].abs() > 1]\n",
    "save_test_result(\"test_\" + basename + \"__charge_changed.xlsx\", test[cols], where=DEBUG_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ASBSO__hjZU7"
   },
   "source": [
    "# Test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z_9N7Xt-jZU8"
   },
   "outputs": [],
   "source": [
    "SPLIT_TEST_INDEX = -1\n",
    "#SPLIT_TEST_INDEX = 11849\n",
    "\n",
    "if SPLIT_TEST_INDEX != -1:\n",
    "    # test split\n",
    "    i = df[df['ID'] == 11849].index.values[0]\n",
    "    #i = df[df['ID'] == 12954].index.values[0]\n",
    "    dup = pd.DataFrame(df.loc[i]).T\n",
    "    #dup = pd.DataFrame(df[df['ID'] == 11849]).T\n",
    "    print(dup[summary])\n",
    "    print()\n",
    "    dup.index.values[0]\n",
    "    split_3(dup)[summary]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iiYX4SthjZVI"
   },
   "source": [
    "# Add flag columns to indicate particular situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Re0rrsDjZVK"
   },
   "outputs": [],
   "source": [
    "# add columns that help to find particular situations\n",
    "df['tmp_needs_split_2'] = df.apply(needs_split_2, axis=1)\n",
    "df['tmp_needs_split_3'] = df.apply(needs_split_3, axis=1)\n",
    "df['tmp_is_night_1'] = df.apply(is_night_1, axis=1)\n",
    "df['tmp_is_night_2'] = df.apply(is_night_2, axis=1)\n",
    "df['tmp_night_discount_applies'] = df.apply(night_discount_applies, axis=1)\n",
    "df['tmp_off_hour_discount_applies'] = df.apply(off_hour_discount_applies, axis=1)\n",
    "df['tmp_includes_holiday_or_weekend'] = df.apply(includes_holiday_or_weekend, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2O18N2QfjZVS"
   },
   "source": [
    "# Search problematic cases and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4302,
     "status": "ok",
     "timestamp": 1586432193240,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "",
      "userId": "10358975484852623681"
     },
     "user_tz": -180
    },
    "id": "h5YfVSAmjZVX",
    "outputId": "b86a39b2-b38d-41d7-cdd9-b1086833d886"
   },
   "outputs": [],
   "source": [
    "def run_tests(tag):\n",
    "    prefix = \"test_\" + basename + \"_\" + tag + \"_\"\n",
    "    # missing a prime/off/night split\n",
    "    test = df[df['tmp_needs_split_3']][summary]\n",
    "    save_test_result(prefix + '_needs_split_3.xlsx', test, where=DEBUG_DIR)\n",
    "\n",
    "    # missing a prime/off split\n",
    "    test = df[df['tmp_needs_split_2']][summary]\n",
    "    save_test_result(prefix + '_needs_split_2.xlsx', test, where=DEBUG_DIR)\n",
    "\n",
    "    # booking includes both night discount periods\n",
    "    test = df[df['tmp_is_night_1'] & df['tmp_is_night_2']][summary]\n",
    "    save_test_result(prefix + '_night1_and_night2.xlsx', test, where=DEBUG_DIR)\n",
    "\n",
    "    # both night discounts and a missing split\n",
    "    test = df[df['tmp_is_night_1'] & df['tmp_is_night_2'] & df['tmp_needs_split_3']][summary]\n",
    "    save_test_result(prefix + '_night1_and_night2_needs_split3.xlsx', test, where=DEBUG_DIR)\n",
    "\n",
    "    # find regular price bookings during holidays\n",
    "    test = df[df['tmp_includes_holiday_or_weekend'] & df['Price item'].str.startswith('Regular usage') & df['tmp_off_hour_discount_applies']][summary]\n",
    "    save_test_result(prefix + '_regular_price_during_holidays.xlsx', test, where=DEBUG_DIR)\n",
    "\n",
    "\n",
    "run_tests(\"_before_fixes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Yd5fxZsjZVj"
   },
   "source": [
    "## Split bookings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z3vj6EWsjZVn"
   },
   "outputs": [],
   "source": [
    "# bookings with missing splits\n",
    "index = df[df['tmp_needs_split_3']].index\n",
    "#print(index)\n",
    "\n",
    "df['tmp_remove_split_line'] = False\n",
    "\n",
    "# dataframe for split bookings\n",
    "splits = pd.DataFrame()\n",
    "for i in index:\n",
    "    #print(i)\n",
    "\n",
    "    y1 = df.loc[i]['Booking start'].year\n",
    "    m1 = df.loc[i]['Booking start'].month\n",
    "    d1 = df.loc[i]['Booking start'].day\n",
    "\n",
    "    #print(df.loc[i]['ID']) \n",
    "    # create a new DataFrame from the line to be split\n",
    "    dup = pd.DataFrame(df.loc[i]).T\n",
    "    \n",
    "    # split the line\n",
    "    split = split_3(dup)\n",
    "    #print(split[summary])\n",
    "    #print(split.shape)\n",
    "    \n",
    "    # mark original line for removal\n",
    "    df.at[i,'tmp_remove_split_line'] = True\n",
    "    \n",
    "    # append the split line to the dataframe with all splits \n",
    "    splits = splits.append(split, ignore_index=True)\n",
    "    \n",
    "# append all splits to the original dataframe\n",
    "df = df.append(splits, ignore_index=True)\n",
    "\n",
    "# save splits including the original line \n",
    "df[df['tmp_needs_split_3'] == True] \\\n",
    "    .sort_values(['ID','Booking start','Quantity'], ascending=[True, True, False])[summary] \\\n",
    "    .to_excel(DEBUG_DIR / (\"tmp_\" + basename + \"__fix1_split\" + ext), index=True) \n",
    "\n",
    "# remove original line and save dataframe\n",
    "df = df[df['tmp_remove_split_line'] == False]\n",
    "df[summary].to_excel(DEBUG_DIR / (\"tmp_\" + basename + \"__fix1_split_originals_removed\" + ext), index=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OQHTCgO8jZVy"
   },
   "source": [
    "## Fix holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OLSw3FFFjZV0"
   },
   "outputs": [],
   "source": [
    "# fix holidays\n",
    "idx = df[df['tmp_includes_holiday_or_weekend'] & ~df['Price item'].str.startswith('Night') & df['tmp_off_hour_discount_applies']].index\n",
    "for i in idx:\n",
    "    #print(df.loc[i]['ID']) \n",
    "    # by eyeballing the list it seems there is no need for splitting, so it's enough to edit the price\n",
    "    df.at[i,'Price item'] = OFF_HOURS\n",
    "    #print(df.loc[i][summary].T)\n",
    "    #print(prices[prices['Instrument'] == df.loc[i][RESOURCE]])\n",
    "    #print(prices[prices['Instrument'] == df.loc[i][RESOURCE]]['Off-hours'])\n",
    "    df.at[i,'Price'] = get_price(df.loc[i]) \n",
    "    df.at[i,'Charge'] = calculate_charge(df.loc[i])\n",
    "    \n",
    "df.loc[idx][summary].to_excel(DEBUG_DIR / (\"tmp_\" + basename + \"__fix2_holidays\" + ext), index=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z_xIv6zmjZWB"
   },
   "source": [
    "## Fix night time discounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6439,
     "status": "ok",
     "timestamp": 1586432195390,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "",
      "userId": "10358975484852623681"
     },
     "user_tz": -180
    },
    "id": "uGdWjFZpjZWE",
    "outputId": "05a54ba0-ffa9-429d-d010-47935188be75"
   },
   "outputs": [],
   "source": [
    "# fix night time reservations that didn't need a split but include both discounts\n",
    "idx = df[df['tmp_is_night_1'] & df['tmp_is_night_2'] & ~df['tmp_needs_split_3']][summary].index\n",
    "for i in idx:\n",
    "    # if booking starts after 22, it's enough to fix price\n",
    "    if(df.loc[i]['Booking start'].hour >= 22):\n",
    "        print(\"fix price and charge for \" + str(df.loc[i]['ID']))\n",
    "        df.at[i,'Price item'] = NIGHT_TIME\n",
    "        df.at[i,'Price'] = get_price(df.loc[i])\n",
    "        df.at[i,'Charge'] = calculate_charge(df.loc[i])\n",
    "    else:\n",
    "        print(\"do nothing, this should have been split \" + str(df.loc[i]['ID']))\n",
    "\n",
    "cols = summary_short.copy()\n",
    "cols.append('tmp_charge_iris')\n",
    "cols.append('tmp_charge_diff')\n",
    "\n",
    "df.loc[idx][cols].to_excel(DEBUG_DIR / (\"tmp_\" + basename + \"__fix3_nights_1_and_2\" + ext), index=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6436,
     "status": "ok",
     "timestamp": 1586432195391,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "",
      "userId": "10358975484852623681"
     },
     "user_tz": -180
    },
    "id": "lWzoEQL2jZWU",
    "outputId": "c5c13a18-d29e-4de8-ecab-e361388fd929"
   },
   "outputs": [],
   "source": [
    "df['tmp_num_issue'] = ~df[\"Price\"].apply(np.isreal)\n",
    "df[df['tmp_num_issue']==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find overlapping bookings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERVAL = 'tmp_booking_interval'\n",
    "OVERLAPS = 'tmp_overlapping_bookings'\n",
    "HAS_OVERLAPS = 'tmp_has_overlapping_bookings'\n",
    "\n",
    "df[OVERLAPS] = ''\n",
    "df[HAS_OVERLAPS] = False\n",
    "\n",
    "def booking_interval(row):\n",
    "    return pd.Interval(left=row['Booking start'], right=row['Booking end'])\n",
    "\n",
    "def overlaps_another_booking(row, testrow):\n",
    "    overlaps = row[OVERLAPS]\n",
    "    if (row[RESOURCE] == testrow[RESOURCE]) \\\n",
    "        & (row['ID'] != testrow['ID']) \\\n",
    "        & (row[INTERVAL].overlaps(testrow[INTERVAL])):\n",
    "        overlaps = overlaps + ',' + str(testrow['ID'])    \n",
    "    return overlaps\n",
    "\n",
    "def find_overlaps(ia):\n",
    "    overlaps = []\n",
    "    \n",
    "    tuples = ia.to_tuples()\n",
    "    #print(tuples)\n",
    "    for i in range(1,len(tuples)-1):\n",
    "        if tuples[i][0] < tuples[i-1][1]:\n",
    "            #print(tuples[i-1])\n",
    "            #print(tuples[i])\n",
    "            overlaps.append(pd.Interval(*tuples[i-1]))\n",
    "            overlaps.append(pd.Interval(*tuples[i]))\n",
    "    \n",
    "    return overlaps\n",
    "\n",
    "df[INTERVAL] = df.apply(booking_interval, axis=1)\n",
    "\n",
    "# Sort bookings by resource and booking period. This allows to use IntervalArray.is_non_overlapping_monotonic below.\n",
    "df = df.sort_values([RESOURCE,'Booking start','Booking end'], ascending=[True, True, True])\n",
    "\n",
    "intervals = {}\n",
    "for r in df[RESOURCE].unique():\n",
    "    dfr = df[df[RESOURCE] == r]\n",
    "    ia = pd.arrays.IntervalArray(dfr[INTERVAL].values)\n",
    "    intervals[r] = ia\n",
    "    \n",
    "    if not ia.is_non_overlapping_monotonic:\n",
    "        print(r + \" has overlapping bookings\")\n",
    "        \n",
    "        overlaps = find_overlaps(ia)\n",
    "        #print(overlaps)\n",
    "        \n",
    "        idx = dfr[dfr[INTERVAL].isin(overlaps)].index\n",
    "        for i in idx:\n",
    "            df.at[i, HAS_OVERLAPS] = True\n",
    "            #print(i)\n",
    "\n",
    "# save bookings with overlaps\n",
    "cols = ['ID','User name',RESOURCE,'Booking start','Booking end','Quantity','tmp_cancellation','tmp_cancellation_fee_applies','tmp_rebooked',OVERLAPS,'Price item','Charge','Discount', 'Comments (charge)','Group','Cost center name','Cost center code']\n",
    "\n",
    "### work on a copy containing only bookings with overlaps\n",
    "dfo = df[df[HAS_OVERLAPS] == True].copy()\n",
    "\n",
    "# loop over bookings that have overlaps\n",
    "for i in dfo.index:\n",
    "    c = dfo.loc[i]\n",
    "    #print(c[INTERVAL])\n",
    "    # find the overlapping bookings: this would take a long time to run on the whole dataframe\n",
    "    dfo[OVERLAPS] = dfo.apply(overlaps_another_booking, testrow=c, axis=1)\n",
    "dfo[cols].to_excel(INVOICE_DIR / (\"test_\" + basename + \"__overlapping_bookings.xlsx\"), index=True)\n",
    "\n",
    "\n",
    "### continue on the complete dataframe\n",
    "# copy overlaps to complete dataframe (magically the indexing works)\n",
    "df[OVERLAPS] = dfo[OVERLAPS]\n",
    "df[cols].to_excel(DEBUG_DIR / (\"tmp_\" + basename + \"__dfo2.xlsx\"), index=True)\n",
    "\n",
    "\n",
    "# test only with lauri\n",
    "#df = df[df['User email'].str.contains('lauri')]\n",
    "\n",
    "#for i in df.index:\n",
    "#idx = df[df[HAS_OVERLAPS].index\n",
    "#for i in idx:\n",
    "#    c = df.loc[i]\n",
    "#    print(c[INTERVAL])\n",
    "#    df[OVERLAPS] = df.apply(overlaps_another_booking, testrow=c, axis=1)\n",
    "\n",
    "#summary.append(OVERLAPS)\n",
    "#df[df[OVERLAPS] != ''][summary]\n",
    "#df[df[OVERLAPS] != ''][summary].to_excel(os.path.join(INVOICE_DIR,\"test_\" + basename + \"__overlapping_bookings2.xlsx\"), index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0r5r8kNjZWc"
   },
   "source": [
    "## Save test files after fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6830,
     "status": "ok",
     "timestamp": 1586432195789,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "",
      "userId": "10358975484852623681"
     },
     "user_tz": -180
    },
    "id": "oj0La_AkjZWe",
    "outputId": "49182ac4-369b-40e3-afd8-02258463fb7d"
   },
   "outputs": [],
   "source": [
    "df['tmp_needs_split_3'] = df.apply(needs_split_3, axis=1)\n",
    "\n",
    "summary.append('tmp_discount_factor')\n",
    "run_tests(\"_after_fixes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8grw4NSHjZWz"
   },
   "source": [
    "## Check total after fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8870,
     "status": "ok",
     "timestamp": 1586432197838,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "",
      "userId": "10358975484852623681"
     },
     "user_tz": -180
    },
    "id": "wIEDt9eTjZW1",
    "outputId": "890fddf1-2874-45d9-cec4-9df2c37be806",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "totals_wbs, df_wbs = check_totals(df,'after_fixes',INVOICE_DIR,basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3EP3TIixjZWq"
   },
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TzUD20rEjZWs"
   },
   "outputs": [],
   "source": [
    "# remove tmp_ columns\n",
    "df = df[df.columns.drop(list(df.filter(regex='tmp_')))]\n",
    "\n",
    "df = df.rename(columns={'Quantity':'Qty'})\n",
    "\n",
    "# save discount as %, not a string\n",
    "df['Discount'] = df['Discount'].str.replace('nan','0')\n",
    "df['Discount'] = df['Discount'].str.replace(' %','')\n",
    "df['Discount'] = df['Discount'].astype(float)\n",
    "# save discount as fraction\n",
    "df['Discount'] = df['Discount'] / 100\n",
    "\n",
    "# sort by original ID\n",
    "#df = df.sort_values(['ID','Booking start','Qty'], ascending=[True, True, False])\n",
    "\n",
    "# sort by time (booking start)\n",
    "df = df.sort_values(['Booking start',RESOURCE], ascending=[True, True])\n",
    "\n",
    "# sort by time (creation date)\n",
    "#df = df.sort_values(['Creation date',RESOURCE], ascending=[True, True])\n",
    "\n",
    "# Append products\n",
    "products = products.rename(columns={'Quantity':'Qty'})\n",
    "df = pd.concat([df, products])\n",
    "total_wbs, df_wbs = check_totals(df,'with_products',INVOICE_DIR,basename)\n",
    "\n",
    "#\n",
    "# Save summary with verifiers\n",
    "# \n",
    "\n",
    "# extract verifiers, save excel for debugging\n",
    "verifiers = df[['Cost center code',COL_REQUESTER_NAME]]\\\n",
    "    .groupby(['Cost center code'])[['Cost center code', COL_REQUESTER_NAME]]\\\n",
    "    .transform(lambda x: ', '.join(sorted(set(x))))\\\n",
    "    .reset_index()\n",
    "verifiers = verifiers.drop(columns=['index'])\n",
    "verifiers = verifiers.drop_duplicates(subset=['Cost center code'], keep='first')\n",
    "verifiers.to_excel(DEBUG_DIR / (\"test_\" + basename + \"__verifiers.xlsx\"), index=False)\n",
    "\n",
    "# create the summary\n",
    "tmp = df.groupby(['Group','Remit code','Cost center code'])['Charge'].sum().reset_index()\n",
    "\n",
    "# add verifiers\n",
    "tmp = pd.merge(tmp, verifiers, on='Cost center code')\n",
    "\n",
    "# save excel\n",
    "tmp = tmp.rename({COL_REQUESTER_NAME:'Verifier name(s)'}, axis=1)\n",
    "tmp.loc['Column_Total']= tmp.sum(numeric_only=True, axis=0)\n",
    "tmp.to_excel(INVOICE_DIR / (\"test_\" + basename + \"__totals_by_group_and_wbs_with_verifiers.xlsx\"), index=False)\n",
    "total_wbs = round(tmp.loc['Column_Total']['Charge'],2)\n",
    "print(\"grouped by WBS: \" + str(total_wbs))\n",
    "\n",
    "\n",
    "# save full fixed version\n",
    "df.to_excel(INVOICE_DIR / (basename + \"_fixed\" + ext), index=False)\n",
    "\n",
    "# if there is no header, read it from disk\n",
    "if header.empty:\n",
    "    header = pd.read_excel(INVOICE_DIR / (basename + '__header.xlsx'))\n",
    "    \n",
    "# fix header total\n",
    "header['Total'] = str(totals_wbs) + \" EUR\"\n",
    "\n",
    "# save header\n",
    "header.to_excel(INVOICE_DIR / (basename + \"__header.xlsx\"), index=False)\n",
    "\n",
    "# save header and data as .csv\n",
    "header.to_csv(DEBUG_DIR / (basename + \"_fixed_header.csv\"), index=False)\n",
    "df.to_csv(DEBUG_DIR / (basename + \"_fixed.csv\"), mode='a', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[df['Cost center code'].apply(lambda x: isinstance(x, int))]\n",
    "save_test_result(\"test_\" + basename + \"__cost_center_code_int.xlsx\", test, where=DEBUG_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl.styles import Alignment, Font\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.worksheet.dimensions import ColumnDimension, DimensionHolder\n",
    "\n",
    "def as_text(value):\n",
    "    if value is None:\n",
    "        return \"\"\n",
    "    return str(value)\n",
    "\n",
    "def adjust_col_width(xlsx):\n",
    "    wb = openpyxl.load_workbook(xlsx)\n",
    "    worksheet = wb['Sheet1']\n",
    "    \n",
    "    for column_cells in worksheet.columns:\n",
    "        length = max(len(as_text(cell.value)) for cell in column_cells)\n",
    "        worksheet.column_dimensions[openpyxl.utils.get_column_letter(column_cells[0].column)].width = length\n",
    "    \n",
    "    for cell in worksheet['D']:\n",
    "        cell.number_format = '####0.00€'\n",
    "        cell.alignment = Alignment(horizontal='right')\n",
    "\n",
    "    wb.save(filename=xlsx)\n",
    "    \n",
    "xlsx = INVOICE_DIR / (\"test_\" + basename + \"__totals_by_group_and_wbs_with_products.xlsx\")\n",
    "print(xlsx)\n",
    "adjust_col_width(xlsx)\n",
    "xlsx = INVOICE_DIR / (\"test_\" + basename + \"__totals_by_group_and_wbs_with_verifiers.xlsx\")\n",
    "print(xlsx)\n",
    "adjust_col_width(xlsx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "pohja = 'Sisäinen_lasku_monta_asiakasta_POHJA.xlsx'\n",
    "ailille = INVOICE_DIR / pohja.replace('POHJA', basename)\n",
    "print(ailille)\n",
    "\n",
    "wb = openpyxl.load_workbook(pohja)\n",
    "ws = wb['Sisäinen lasku, monta asiakasta']\n",
    "\n",
    "ws['B10'] = 'H919'\n",
    "ws['B12'] = 'Light Microscopy Unit'\n",
    "ws['B14'] = 'Viikinkaari 5'\n",
    "ws['B16'] = 'Mika Molin'\n",
    "\n",
    "internal = \"^H[0-9]{2,22}\"\n",
    "df_int = df[df['Remit code'].str.contains(internal, regex=True)]\n",
    "GROUP = 'Group'\n",
    "HEADS = 'Group head(s) text'\n",
    "EMAIL = 'Email'\n",
    "grp_and_heads = df_int.drop_duplicates(subset=[GROUP])[[GROUP, HEADS]]\n",
    "\n",
    "\n",
    "# split group name to first and last name, replace ääkköset, construct email addresses\n",
    "grp_and_heads[['Last', 'First']] = grp_and_heads[GROUP].str.rsplit(' ', 1, expand=True)\n",
    "tdict = {'ä':'a', 'ö':'o', 'å':'a'}\n",
    "ttable = \"äöå\".maketrans(tdict)\n",
    "grp_and_heads['First'] = grp_and_heads['First'].str.translate(ttable)\n",
    "grp_and_heads['Last'] = grp_and_heads['Last'].str.translate(ttable)\n",
    "grp_and_heads['first'] = grp_and_heads['First'].str.lower()\n",
    "grp_and_heads['fast'] = grp_and_heads['Last'].str.lower()\n",
    "grp_and_heads['First.Last'] = grp_and_heads['First'] + '.' + grp_and_heads['Last'] + '@helsinki.fi'\n",
    "grp_and_heads['first.last'] = grp_and_heads['first'] + '.' + grp_and_heads['fast'] + '@helsinki.fi'\n",
    "\n",
    "# initialize Contact as all Group heads\n",
    "grp_and_heads['Contact'] = grp_and_heads[HEADS]\n",
    "\n",
    "# function to remove constructed email addresses from group heads\n",
    "def subtract_email(row):\n",
    "    heads = str(row[HEADS])\n",
    "    email = str(row['first.last'])\n",
    "    Email = str(row['First.Last'])\n",
    "    #print(heads)\n",
    "    #print(email)\n",
    "    heads = heads.replace(email,'')\n",
    "    heads = heads.replace(Email,'')\n",
    "    # this will mess up cases with two added heads (e.g. Alitalo), majority looks ok\n",
    "    heads = heads.replace(' ','')\n",
    "    heads = heads.replace(';','')\n",
    "    #heads = heads.replace('; ','')\n",
    "    heads = re.sub('helsinki.fi?', 'helsinki.fi; ', heads)\n",
    "    \n",
    "    return heads\n",
    "\n",
    "grp_and_heads['AddedContact'] = grp_and_heads.apply(subtract_email, axis=1)\n",
    "added_contacts = grp_and_heads[(grp_and_heads['AddedContact'].str.len()>0)]\n",
    "for i in added_contacts.index:\n",
    "    grp_and_heads.at[i,'Contact'] = added_contacts.at[i,'AddedContact']\n",
    "\n",
    "def get_contact(table, group):\n",
    "    contact = table[table['Group']==group]['Contact'].values[0]\n",
    "    return str(contact)\n",
    "\n",
    "#print(get_contact(grp_and_heads, 'Ojala Päivi'))\n",
    "\n",
    "\n",
    "internal = re.compile(\"H[0-9]{2,22}\")\n",
    "\n",
    "# start filling in invoice lines from this row\n",
    "i = 9\n",
    "for index, row in df_wbs.iterrows():\n",
    "    if not internal.match(str(row['Remit code'])):\n",
    "        continue\n",
    "        \n",
    "    ws['J' + str(i)] = row['Remit code']\n",
    "    ws['K' + str(i)] = row['Group']\n",
    "    ws['L' + str(i)] = get_contact(grp_and_heads, row['Group'])\n",
    "    ws['M' + str(i)] = row['Cost center code']\n",
    "    ws['Q' + str(i)] = \"%s %s.xlsx\" % (row['Group'], row['Cost center code'])\n",
    "    ws['R' + str(i)] = row['Charge']\n",
    "    \n",
    "    i = i+1\n",
    "\n",
    "wb.save(filename=ailille)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_and_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "billing_checks_and_fixes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
