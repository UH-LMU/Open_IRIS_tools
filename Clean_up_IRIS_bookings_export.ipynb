{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "datadir = Path(\"\")\n",
    "\n",
    "DATA_DIR = './2020'\n",
    "# bookings20200515092345.csv: \n",
    "# - selected date range in IRIS: 2019.01.01 - 2019.12.31\n",
    "# - all providers\n",
    "#export = \"bookings20200515092345.csv\"\n",
    "\n",
    "# bookings20200515134423.csv\n",
    "# - selected range in IRIS: 2018.12.01 - 2019.12.31\n",
    "# - only LMU\n",
    "DATA_NAME = 'bookings20200515134423.csv' \n",
    "\n",
    "DATA_DIR = Path(DATA_DIR)\n",
    "if not DATA_DIR.is_dir():\n",
    "    raise ValueError('Please check DATA_DIR.')\n",
    "DATA_FILE = DATA_DIR / DATA_NAME\n",
    "if not DATA_FILE.exists():\n",
    "    raise ValueError('Please check DATA_NAME.')\n",
    "\n",
    "df = pd.read_csv(DATA_FILE, na_values='', skiprows=1)\n",
    "print(df.shape)\n",
    "\n",
    "# keep only LMU data\n",
    "df = df[df['Provider'] == 'Light Microscopy Unit']\n",
    "\n",
    "# select a date range\n",
    "START = '2019-01-01'\n",
    "END = '2020-01-01'\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/35321812/move-column-in-pandas-dataframe/35322540\n",
    "from pandas import DataFrame\n",
    "\n",
    "def move_columns(df: DataFrame, cols_to_move: list, new_index: int) -> DataFrame:\n",
    "    \"\"\"\n",
    "    This method re-arranges the columns in a dataframe to place the desired columns at the desired index.\n",
    "    ex Usage: df = move_columns(df, ['Rev'], 2)   \n",
    "    :param df:\n",
    "    :param cols_to_move: The names of the columns to move. They must be a list\n",
    "    :param new_index: The 0-based location to place the columns.\n",
    "    :return: Return a dataframe with the columns re-arranged\n",
    "    \"\"\"\n",
    "    other = [c for c in df if c not in cols_to_move]\n",
    "    start = other[0:new_index]\n",
    "    end = other[new_index:]\n",
    "    return df[start + cols_to_move + end]\n",
    "\n",
    "\n",
    "# convert the 'Date' column to datetime format \n",
    "df['Start']= pd.to_datetime(df['Start']) \n",
    "df['End']= pd.to_datetime(df['End']) \n",
    "df['Duration'] = df['End'] - df['Start']\n",
    "\n",
    "# apply date range\n",
    "df = df[(df['Start'] >= datetime.fromisoformat(START + 'T00:00:00')) & \\\n",
    "        (df['End'] < datetime.fromisoformat(END + 'T00:00:00'))].copy()\n",
    "\n",
    "# calculate duration in hours\n",
    "df['DurationH'] = df.apply(lambda row: row.Duration.total_seconds() / 3600, axis=1)\n",
    "df['DurationH'] = df['DurationH'].round(decimals=1)\n",
    "# drop timedelta column\n",
    "df = df.drop(columns=['Duration'])\n",
    "# rename hours column\n",
    "df = df.rename(columns={\"DurationH\": \"Duration\"})\n",
    "\n",
    "df = move_columns(df,['Duration'], 4)\n",
    "\n",
    "\n",
    "\n",
    "# remove lines where resource is an add-on\n",
    "addons = [ \\\n",
    "          #\"3I Marianas base with lasers\", \"3I Marianas no lasers \", \n",
    "          \"3I Marianas\", \\\n",
    "          \"3I 405\", \"3I 488\", \"3I 561\", \"3I 640\", \"3I marianas no laser add-on\",\"3I marianas no lasers\", \\\n",
    "          \"Zeiss Z.1 LightSheet Lasers\", \"Light sheet 405\", \"Light sheet 445\", \"Light sheet 488\", \"Light sheet 514\", \"Light sheet 561\", \"Light sheet 640\", \"Light sheet no laser add on\", \"Zeiss Z.1 LightSheet Data management\", \\\n",
    "          \"LSM700 405\", \"LSM700 488\",\"LSM700 555\",\"LSM700 639\", \\\n",
    "          \"SP5 HCS-A 405\", \"SP5 HCS-A Argon\",\"SP5 HCS-A 561\",\"SP5 HCS-A 633\", \\\n",
    "          \"SP5 MP 405\", \"SP5 MP Argon\", \"SP5 MP 561\", \"SP5 MP 594\", \"SP5 MP 633\", \"SP5 MP Laser MP\", \\\n",
    "          \"SP8  STED 592 STED\", \"SP8 STED 405\", \"SP8 STED Argon\",\"SP8 STED 561\",\"SP8 STED 633\", \\\n",
    "          \"SP8 upright 405\", \"SP8 upright 488 \", \"SP8 upright 488\", \"SP8 upright 552\", \"SP8 upright 638\", \\\n",
    "          \"No laser (admin only)\", \\\n",
    "          \"Sheep (TESTING AND DEVELOPMENT PURPOSE\", \"Super testers practice instrument\", \\\n",
    "         \"GE and DM5000 Room 2028,2\", \"Leica SP5II HCA and SP8 Upright, Room 2036b\"]\n",
    "df = df[~df['Resource'].isin(addons)]\n",
    "\n",
    "# remove lines with booking status that should be ignored\n",
    "ignore_statuses = [\"Canceled\", \"Upcoming\", \"Undefined\"]\n",
    "df = df[~df['Status'].isin(ignore_statuses)]\n",
    "\n",
    "# remove test groups\n",
    "ignore_groups = [\"Group Raimi research inc\", \"TEST Viktor\"]\n",
    "df = df[~df['Group'].isin(ignore_groups)]\n",
    "\n",
    "# remove IRIS admin bookings\n",
    "df = df[~df['BookedBy'].isin(['iris@science-it.ch'])]\n",
    "\n",
    "\n",
    "\n",
    "# save maintenance bookings\n",
    "df2 = df[df['Type'].str.contains(\"Maintenance\")]\n",
    "OUTPUT = DATA_DIR / (DATA_FILE.stem + \"__\" + START + \"__\" + END + \"__maintenance\" + DATA_FILE.suffix)\n",
    "df2.to_csv(OUTPUT, index=False, na_rep='')\n",
    "\n",
    "# remove maintenance bookings from original\n",
    "df = df[~df['Type'].str.contains(\"Maintenance\")]\n",
    "\n",
    "\n",
    "# save as CSV\n",
    "OUTPUT = DATA_DIR / (DATA_FILE.stem + \"__\" + START + \"__\" + END + DATA_FILE.suffix)\n",
    "df.to_csv(OUTPUT, index=False, na_rep='')\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "# save uniques group / user pairs\n",
    "df2 = df[['Group','User']]\n",
    "df2 = df2.sort_values(['Group', 'User'], ascending=[True, True]).drop_duplicates()\n",
    "df2['Booked group'] = df2.apply(lambda row: row.Group.split()[-1], axis=1)\n",
    "OUTPUT = DATA_DIR / (DATA_FILE.stem + \"__\" + START + \"__\" + END + \"__unique_group_user\" + DATA_FILE.suffix)\n",
    "df2.to_csv(OUTPUT, index=False)\n",
    "\n",
    "\n",
    "# calculate group totals\n",
    "df2 = df.groupby([\"Group\"]).sum()\n",
    "df2['Duration'] = df2['Duration'].round(decimals=0)\n",
    "df2.index.names = ['Group']\n",
    "df2 = df2.rename(columns={\"Duration\": \"IRIS total hours\"})\n",
    "#df2 = df2.drop(columns=['Request ID','Products', 'Project'])\n",
    "df2 = df2.drop(columns=['Request ID','Operator','Products', 'Project'])\n",
    "\n",
    "df2.reset_index(inplace=True)\n",
    "df2['Booked group'] = df2.apply(lambda row: row.Group.split()[-1], axis=1)\n",
    "\n",
    "OUTPUT = DATA_DIR / (DATA_FILE.stem + \"__\" + START + \"__\" + END + \"__group_totals\" + DATA_FILE.suffix)\n",
    "df2.to_csv(OUTPUT, index=True, na_rep='')\n",
    "\n",
    "\n",
    "#df3 = pd.DataFrame()\n",
    "#df3['IRIS_group'] = sorted(df.Group.unique())\n",
    "#df3['IRIS_total_hours'] = df3.apply(lambda row: row.IRIS_group, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to check difference between dataframe (works if there are no duplicates in the dfs themselves).\n",
    "#df3 = pd.concat([df,df2019]).drop_duplicates(keep=False)\n",
    "\n",
    "# diff between dataframes (see cell above)\n",
    "#df3[['Date of booking','Resource', 'Start','End','User']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which 3I entries have price info\n",
    "tmp = df[df.Resource.str.startswith(\"3I Marianas\") & (~df.Charges.isnull()) ]\n",
    "print(tmp[\"Resource\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find bookings that are longer than 1 day\n",
    "day = pd.Timedelta(\"1 day\")\n",
    "df[df[\"Duration\"] > day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that add-ons are gone\n",
    "print(sorted(df.Resource.unique()))\n",
    "# check that cancellations and upcoming bookings are gone\n",
    "print(sorted(df.Status.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find bookings since lass billing with no WBS\n",
    "previous_billing_date = '2019-5-23'\n",
    "df[df[\"Cost center\"].isnull() & ((df.Start > previous_billing_date))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find bookings by LMU staff\n",
    "lmu_staff = [\"Harri.Jaalinoja@helsinki.fi\", \"marko.crivaro@helsinki.fi\", \"kimmo.tanhuanpaa@helsinki.fi\", \"mika.molin@helsinki.fi\", \"viktor.raimi@helsinki.fi\"]\n",
    "df[df['User'].isin(lmu_staff)][['Start','End','Resource','Group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
